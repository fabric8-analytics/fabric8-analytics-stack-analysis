FROM quay.io/openshiftio/fabric8-analytics-stack-analysis:latest
MAINTAINER Avishkar Gupta <avgupta@redhat.com>

# --------------------------------------------------------------------------------------------------
# copy testing source code and scripts into root dir /
# --------------------------------------------------------------------------------------------------
ADD ./tests/ /tests
ADD ./tools/ /tools
ADD ./tests/scripts/entrypoint-test.sh /entrypoint-test.sh
ADD .git /.git
RUN chmod +x /entrypoint-test.sh

# Begin spark installation
RUN yum install -y java-1.8.0-openjdk.x86_64 java-1.8.0-openjdk-devel.x86_64 wget git && \
    wget https://downloads.lightbend.com/scala/2.12.2/scala-2.12.2.tgz && \
    tar -xvf scala-2.12.2.tgz && \
    mv scala-2.12.2 /usr/local/scala && \
    wget https://archive.apache.org/dist/spark/spark-2.1.1/spark-2.1.1-bin-hadoop2.7.tgz && \
    tar -xvf spark-2.1.1-bin-hadoop2.7.tgz && \
    mv spark-2.1.1-bin-hadoop2.7 /usr/local/spark

RUN export java_version="`ls /usr/lib/jvm` | grep java-1.8.0-openjdk-"
RUN export JAVA_HOME="/usr/lib/jvm/${java_version}/jre"
ENV SPARK_HOME=/usr/local/spark
ENV PATH=/usr/local/maven/bin:$JAVA_HOME/bin:$SPARK_HOME/bin:/usr/local/scala/bin:$PATH
ENV PYTHONPATH=.

# --------------------------------------------------------------------------------------------------
# install python packages
# --------------------------------------------------------------------------------------------------
COPY ./test_requirements.txt /
RUN python -m pip install -r /test_requirements.txt

# --------------------------------------------------------------------------------------------------
# RUN THE UNIT TESTS
# --------------------------------------------------------------------------------------------------
ENTRYPOINT ["/entrypoint-test.sh"]
